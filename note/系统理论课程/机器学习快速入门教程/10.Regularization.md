# 正则化

## 概述

降低复杂模型的复杂度来防止过拟合，这种原则称为**正则化**。

也就是说，并非只是以最小化损失（经验风险最小化）为目标：$$minimize(Loss(Data[Model]))$$

而是以最小化损失和复杂度为目标，这称为**结构风险最小化**：$$minimize(Loss(Data[Model]) + complexity(Model))$$

现在，我们的训练优化算法是一个由两项内容组成的函数：

- 一个是**损失项**，用于衡量模型与数据的拟合度；
- 另一个是**正则化项**，用于衡量模型复杂度。

机器学习速成课程重点介绍了两种衡量模型复杂度的常见方式（这两种方式有些相关）：

- 将模型复杂度作为模型中所有特征的权重的函数。
- 将模型复杂度作为具有非零权重的特征总数的函数。（[后面的一个单元](https://developers.google.cn/machine-learning/crash-course/regularization-for-sparsity/l1-regularization)介绍了这种方法。）

如果模型复杂度是权重的函数，则特征权重的绝对值越高，对模型复杂度的贡献就越大。

## L2 正则化

我们可以使用 **L2 正则化** 公式来量化复杂度，该公式将正则化项定义为所有特征权重的平方和：

$$L_2\ regularization\ term=||w||^2_2=w_1^2+w_2^2+...+w_n^2$$

在这个公式中，接近于 0 的权重对模型复杂度几乎没有影响，而离群值权重则可能会产生巨大的影响。

## 简化正则化 `lambda`

模型开发者通过以下方式来调整正则化项的整体影响：用正则化项的值乘以名为 **lambda**（又称为**正则化率**）的标量。也就是说，模型开发者会执行以下运算：

$$minimize(Loss(Data[Model]) + \lambda complexity(Model))$$

在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：

- 如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。
- 如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。

**注意**：将 lambda 设为 0 可彻底取消正则化。 在这种情况下，训练的唯一目的将是最小化损失，而这样做会使过拟合的风险达到最高。

理想的 lambda 值生成的模型可以很好地泛化到以前未见过的新数据。 遗憾的是，理想的 lambda 值取决于数据，因此您需要手动或自动进行一些调整。

## 关键词

[泛化曲线](https://developers.google.cn/machine-learning/glossary#generalization_curve)、[L2 正则化](https://developers.google.cn/machine-learning/glossary#l2_regularization)、[过拟合](https://developers.google.cn/machine-learning/glossary#overfitting)、[正则化](https://developers.google.cn/machine-learning/glossary#regularization)、[结构风险最小化](https://developers.google.cn/machine-learning/glossary#SRM)、[早停法](https://developers.google.cn/machine-learning/glossary#early_stopping)、[lambda](https://developers.google.cn/machine-learning/glossary#lambda)、[正则化率](https://developers.google.cn/machine-learning/glossary#regularization_rate)

